{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply pre-trained priors for MRI image reconstruction\n",
    "**Authors**: [Guanxiong Luo](mailto:guanxiong.luo@med.uni-goettingen.de), [Nick Scholand](mailto:nick.scholand@med.uni-goettingen.de), [Christian Holme](mailto:christian.holme@med.uni-goettingen.de)\n",
    "\n",
    "**Will take around 30 mins to go through this tutorial.**\n",
    "\n",
    "**Have fun with it! If you have any questions, don't hesitate to drop us a line.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up the environment\n",
    "### a. Download and Compile `bart`\n",
    "If you are running this notebook in the environment that has bart already installed, there is no need run this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Install BARTs dependencies\n",
    "apt-get install -y make gcc libfftw3-dev liblapacke-dev libpng-dev libopenblas-dev &> /dev/null\n",
    "\n",
    "# Download BART version\n",
    "[ -d /content/bart ] && rm -r /content/bart\n",
    "git clone https://github.com/mrirecon/bart/ bart\n",
    "[ -d \"bart\" ] && echo \"BART was downloaded successfully.\"\n",
    "\n",
    "cd bart\n",
    "make &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After compilation of BART we need to set the required environmental variable: `TOOLBOX_PATH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%env TOOLBOX_PATH=/content/bart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we add the compiled `bart` executable to our `PATH` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH'] = os.environ['TOOLBOX_PATH'] + \":\" + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if bart toolbox is working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "bart version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Install `spreco`\n",
    "Download the package spreco and install it with the `pip` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip uninstall tensorflow-gpu\n",
    "pip install tensorflow-gpu==2.4.1\n",
    "git clone https://github.com/mrirecon/spreco.git\n",
    "cd spreco\n",
    "pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl https://zenodo.org/record/6521188/files/pre-trained.tar?download=1 --output pre-trained.tar\n",
    "curl https://zenodo.org/record/6521188/files/full_kspace.npz?download=1 --output full_kspace.npz\n",
    "mkdir spreco/data\n",
    "tar xf pre-trained.tar -C spreco/data\n",
    "mv full_kspace.npz spreco/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Execute reconstruction\n",
    "### a. Import modules \n",
    "\n",
    "`ops` contains simple functionalities for building the forward operator for the k-space measurement $\\mathbf{y}=\\mathcal{A}\\mathbf{x}+\\epsilon$.\n",
    "\n",
    "`sde` contains the class for training reverse transitions $p_\\theta(\\mathbf{x}_i|\\mathbf{x}_{i+1})$.\n",
    "\n",
    "`posterior_sampler` contains the class for simulating samples from $p({\\mathbf{x}|\\mathbf{y}})$ given the learned transitions and the measured k-space.\n",
    "\n",
    "`utils` contains utilities for the calling to bart, loading configuration, converting complex arrays to float arrays and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from spreco.common import ops, sampling_pattern, utils\n",
    "from spreco.model.sde import sde, posterior_sampler\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Load the configuration for reconstruction\n",
    "\n",
    "The configuration file for reconstruction specifies the following options.\n",
    "\n",
    "1. which model is used to construct transition kernel?\n",
    "2. which sampling pattern is used?\n",
    "3. how many samples will be drawn from the posterior?\n",
    "4. where to store the results?\n",
    "5. the values of K, N, $\\lambda$ in the proposed algorithm?\n",
    "6. whether to use burn-in phase, at which time point to be burned?\n",
    "7. where is the k-space data?\n",
    "\n",
    "Example for the recon config file.\n",
    "\n",
    "```yaml\n",
    "cal: 20         # calibration region\n",
    "fx: 1.5         # if possion sampling is used, acceleration along x direction\n",
    "fy: 1.5         # if possion sampling is used, acceleration along y direction\n",
    "poisson: true   # possion sampling pattern\n",
    "sampling_rate: 0.2  # if possion samples is not used, use Gaussian sampling pattern instead\n",
    "s_stepsize: 25  # $\\lambda$ in Algorithm 1\n",
    "st: 30          # N=100-st in Algorithm 1\n",
    "c_steps: 5      # K in Algorithm 1\n",
    "nr_samples: 10  # how many samples will be drawn\n",
    "burn_in: false\n",
    "burn_t: 0.5     # at which time point to be burn\n",
    "disable_z: True\n",
    "target_snr: 1\n",
    "\n",
    "model_folder: xxxx\n",
    "model_name: xxx\n",
    "ksp_path: xxx    # kspace location\n",
    "gpu_id: '3'\n",
    "```\n",
    "\n",
    "check your `recon_config` file, especially the params for the location of kspace and model, and load the configuration with `utils`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "config_path  ='/content/spreco/scripts/recon_config.yaml'\n",
    "config       = utils.load_config(config_path)\n",
    "model_config = utils.load_config(config['model_folder']+'/config.yaml')\n",
    "\n",
    "model_path   = os.path.join(config['model_folder'], config['model_name'])\n",
    "np.random.seed(model_config['seed'])\n",
    "np.random.seed(model_config['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Prepare the undersampled k-space data\n",
    "\n",
    "1. load the fully sampled k-space\n",
    "2. generate the undersampling mask with `bart` or `sampling_pattern`\n",
    "3. compute coil sensitivities with `ecalib`\n",
    "4. build the operator for the k-space measurement.\n",
    "5. compute the ground truth from fully sampled k-space and zero-filled from undersampled k-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_simu(config, mask=None):\n",
    "        \n",
    "    kspace = np.squeeze(np.load(config['ksp_path'])['kspace'])\n",
    "\n",
    "    nx, ny, _ = kspace.shape\n",
    "    coilsen = np.squeeze(utils.bart(1, 'ecalib -m1 -r20 -c0.001', kspace[np.newaxis, ...]))\n",
    "    img_shape = [nx, ny]\n",
    "    std_coils = ops.mifft2(kspace, img_shape)\n",
    "\n",
    "    rss = np.sum(np.multiply(std_coils, np.squeeze(np.conj(coilsen))), axis=2)\n",
    "\n",
    "    if mask is None:\n",
    "        if not config['poisson']:\n",
    "            mask = sampling_pattern.gen_mask_2D(nx, ny, center_r = config['cal'], undersampling = config['sampling_rate'])\n",
    "        else:\n",
    "            mask = utils.bart(1, 'poisson -Y %d -Z %d -y %f -z %f -s 1234 -v -C %d'%(nx, ny, config['fx'], config['fy'], config['cal']))\n",
    "            mask = np.squeeze(mask)\n",
    "\n",
    "    und_ksp = kspace*abs(mask[..., np.newaxis])\n",
    "\n",
    "    coilsen = np.squeeze(utils.bart(1, 'ecalib -m1 -r20 -c0.001', kspace[np.newaxis, ...]))\n",
    "    coilsen = np.squeeze(coilsen)\n",
    "    x_ = ops.AT_cart(und_ksp, coilsen, mask, img_shape)\n",
    "\n",
    "    return x_, mask, coilsen, (nx, ny), rss, und_ksp\n",
    "\n",
    "zero_filled, mask, coilsen, shape, rss, und_ksp = prepare_simu(config)\n",
    "zero_filled = utils.float2cplx(utils.normalize_with_max(zero_filled)) # [-1, 1]\n",
    "l1_recon    = utils.bart(1, 'pics -l1 -r 0.01', und_ksp[:,:,np.newaxis,:], coilsen[:,:,np.newaxis,:])\n",
    "\n",
    "grad_params = {'coilsen': coilsen[np.newaxis, ...], 'mask': mask[np.newaxis, ...], 'shape': shape, 'center': False}\n",
    "AHA         = partial(ops.AHA, **grad_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Run the sampler for $p(\\mathbf{x}|\\mathbf{y})$\n",
    "\n",
    "1. create two placeholders for the image $\\mathbf{x}$ and noise indices $i$\n",
    "2. instantiate the neural network\n",
    "3. restore the pre-trained model\n",
    "4. run the sampler with the learned transitions and the measured k-space.\n",
    "5. save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "## network\n",
    "x          = tf.placeholder(tf.float32, shape=[None]+model_config['input_shape']) \n",
    "t          = tf.placeholder(tf.float32, shape=[None]) \n",
    "ins_sde    = sde(model_config)\n",
    "_          = ins_sde.net.forward(x, t)\n",
    "all_params = tf.trainable_variables()\n",
    "saver      = tf.train.Saver()\n",
    "sess       = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, os.path.join(config['model_folder'], config['model_name']))\n",
    "\n",
    "ins_sampler = posterior_sampler(ins_sde, \n",
    "                            steps      = config['c_steps'],\n",
    "                            target_snr = config['target_snr'],\n",
    "                            nr_samples = config['nr_samples'],\n",
    "                            burn_in    = config['burn_in'],\n",
    "                            burn_t     = config['burn_t'],\n",
    "                            ode        = False if 'ode' not in config.keys() else config['ode'],\n",
    "                            ext_iter   = 0 if 'ext_iter' not in config.keys() else config['ext_iter'], \n",
    "                            disable_z        = False if 'disable_z' not in config.keys() else config['disable_z'],\n",
    "                            use_pixelcnn     = False if 'use_pixelcnn' not in config.keys() else config['use_pixelcnn'])\n",
    "\n",
    "images = ins_sampler.conditional_ancestral_sampler(x, t, sess, AHA, zero_filled[np.newaxis, ...], config['s_stepsize'], st=config['st'])\n",
    "\n",
    "if config['burn_in']:\n",
    "    idx = int(ins_sampler.sde.N*config['burn_t']*config['c_steps']) - config['c_steps']\n",
    "    images = utils.float2cplx(np.array(images[-idx:]))\n",
    "else:\n",
    "    images = np.array(images)\n",
    "    images = images[...,0]+1.0j*images[...,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results\n",
    "\n",
    "1. normalize reconstruction \n",
    "2. plot the curves to track PSNR and SSIM over iterations\n",
    "3. compare reconstruction\n",
    "4. plot image over intermediate distributions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Normalize reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# normalize the results\n",
    "mag_rets = np.abs(images)/np.max(abs(images), axis=(2,3))[..., np.newaxis, np.newaxis]\n",
    "mag_rss         = abs(rss)\n",
    "normalized_zero_filled=abs(zero_filled/np.linalg.norm(zero_filled))\n",
    "normalized_l1_recon=abs(l1_recon/np.linalg.norm(l1_recon))\n",
    "normalized_rss  = mag_rss/np.linalg.norm(mag_rss)\n",
    "normalized_rets = mag_rets/np.linalg.norm(mag_rets, axis=(2,3), keepdims=True)\n",
    "\n",
    "total_steps = mag_rets.shape[0]\n",
    "step_size = 1\n",
    "\n",
    "normalized_expectation_1  = normalized_rets[:total_steps:step_size,0,...]\n",
    "normalized_expectation_2  = np.mean(normalized_rets[:total_steps:step_size,0:2,...], axis=1)\n",
    "normalized_expectation_4  = np.mean(normalized_rets[:total_steps:step_size,1:4,...], axis=1)\n",
    "normalized_expectation_8  = np.mean(normalized_rets[:total_steps:step_size,1:8,...], axis=1)\n",
    "normalized_expectation_10 = np.mean(normalized_rets[:total_steps:step_size], axis=1)\n",
    "\n",
    "# calculate psnrs and ssims\n",
    "\n",
    "psnrs=[]\n",
    "ssims=[]\n",
    "\n",
    "for i in range(int(total_steps/step_size)):\n",
    "    tmp_psnr=[]\n",
    "    tmp_ssim=[]\n",
    "    tmp_psnr.append(utils.psnr(normalized_expectation_1[i], normalized_rss))\n",
    "    tmp_ssim.append(utils.ssim(normalized_expectation_1[i], normalized_rss))\n",
    "\n",
    "    tmp_psnr.append(utils.psnr(normalized_expectation_2[i], normalized_rss))\n",
    "    tmp_ssim.append(utils.ssim(normalized_expectation_2[i], normalized_rss))\n",
    "\n",
    "    tmp_psnr.append(utils.psnr(normalized_expectation_4[i], normalized_rss))\n",
    "    tmp_ssim.append(utils.ssim(normalized_expectation_4[i], normalized_rss))\n",
    "\n",
    "    tmp_psnr.append(utils.psnr(normalized_expectation_8[i], normalized_rss))\n",
    "    tmp_ssim.append(utils.ssim(normalized_expectation_8[i], normalized_rss))\n",
    "\n",
    "    tmp_psnr.append(utils.psnr(normalized_expectation_10[i], normalized_rss))\n",
    "    tmp_ssim.append(utils.ssim(normalized_expectation_10[i], normalized_rss))\n",
    "    psnrs.append(tmp_psnr)\n",
    "    ssims.append(tmp_ssim)\n",
    "\n",
    "psnrs = np.array(psnrs)\n",
    "ssims = np.array(ssims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Plot the curves to track PSNR and SSIM over iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['text.usetex'] = False\n",
    "import math\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5.7), gridspec_kw={'width_ratios': [1, 1]})\n",
    "fontsize = 17\n",
    "ticksize = 12\n",
    "for i,c in enumerate([1,2,4,8,10]):\n",
    "    ax1.plot(psnrs[:,i], label= \"{} sample\".format(c) if c==1 else \"{} samples\".format(c))\n",
    "    ax2.plot(ssims[:,i], label= \"{} sample\".format(c) if c==1 else \"{} samples\".format(c))\n",
    "\n",
    "ax1.set_xlabel('iteration', fontsize=fontsize)\n",
    "ax1.set_ylabel('PSNR', fontsize=fontsize)\n",
    "ax1.tick_params(labelsize=ticksize) \n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "ax2.set_xlabel('iteration', fontsize=fontsize)\n",
    "ax2.set_ylabel('SSIM', fontsize=fontsize)\n",
    "ax2.tick_params(labelsize=ticksize) \n",
    "ax2.legend(loc='lower right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Compare reconstruction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def subplot(ax, img, title, cmap, interpolation, vmin, vmax):\n",
    "    ax.imshow(img, cmap=cmap, interpolation=interpolation, vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "rss_max = np.max(normalized_rss)\n",
    "plot_params = {'cmap': 'gray', 'interpolation': 'none', 'vmin': 0, 'vmax': rss_max}\n",
    "axplot      = partial(subplot, **plot_params)\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(20, 7.6), gridspec_kw={'width_ratios': [1, 1, 1, 1]})\n",
    "axplot(ax1, normalized_zero_filled, title='zero filled')\n",
    "axplot(ax2, normalized_l1_recon, title='l1-ESPIRiT in wavelet domain')\n",
    "axplot(ax3, normalized_expectation_10[-1], '{x}_{MMSE}')\n",
    "axplot(ax4, normalized_rss, 'truth')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Create grid of samples and generative the gif for iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "samples = normalized_rets[::35,...]\n",
    "\n",
    "fig, axss = plt.subplots(10, 10, figsize=(15, 15), gridspec_kw={'width_ratios': [1 for _ in range(10)]})\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i==0:\n",
    "            strs='x_%d'%j\n",
    "        else:\n",
    "            strs=''\n",
    "        axplot(axss[i,j], samples[i,j], title=strs)\n",
    "plt.tight_layout(pad=.1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
